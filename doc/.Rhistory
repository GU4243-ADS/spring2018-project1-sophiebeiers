test1
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(gapminder)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(gapminder)
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp))
p <- ggplot(gapminder, aes(x = gdpPercap, y = lifeExp))
p <- ggplot(gapminder, aes(x = gdpPercap, y = lifeExp))
p <- p + geom_point() # then tell it what to map
p <- p + scale_x_log10()
p <- ggplot(gapminder, aes(x = gdpPercap, y = lifeExp))
p <- p + geom_point() # then tell it what to map
p <- p + scale_x_log10()
p
p <- p + geom_point(aes(color = continent))
p
p <- ggplot(gapminder, aes(x = gdpPercap, y = lifeExp))
p <- p + geom_point(aes(color = continent)) # then tell it what to map
p <- p + scale_x_log10()
p <- p + geom_smooth() # goes through
p
install.packages("ggthemes")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(gapminder)
library(ggthemes)
p <- s
s <- p
s + theme_economist()
s
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
cat("\nCXXFLAGS=-O3 -mtune=native -march=native",
"CXXFLAGS= -Wno-unused-variable -Wno-unused-function  -Wno-macro-redefined",
file = M, sep = "\n", append = TRUE)
cat("\nCC=clang",
"CXX=clang++ -arch x86_64 -ftemplate-depth-256",
file = M, sep = "\n", append = TRUE)
cat(readLines(M), sep = "\n")
cat(M)
getwd
getwd()
library(digest)
?digest
setwd("~/Documents/GitHub/spring2018-project1-sophiebeiers/doc")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
packages.used <- c("ggplot2", "dplyr", "tibble", "tidyr",  "stringr", "tidytext", "topicmodels", "wordcloud", "ggridges", "sentimentr", "tm", "caret", "topicmodels")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0) {
install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}
library(ggplot2)
library(dplyr)
library(tibble)
library(tidyr)
library(stringr)
library(tidytext)
library(topicmodels)
library(wordcloud)
library(ggridges)
library(sentimentr)
library(tm)
library(caret)
library(topicmodels)
source("../lib/multiplot.R")
spooky <- read.csv('../data/spooky.csv', as.is = TRUE)
#sum(is.na(spooky)) # no NA's in data
spooky$author <- as.factor(spooky$author) # Make "author" a factor
spooky_wrd <- spooky %>%
unnest_tokens(word, text) %>%
count(author, word, sort = TRUE) %>% # sorts by most common words
ungroup()
pronouns <- c("i", "we", "us", "they", "them", "he", "she", "you", "him", "her")
spooky_pronouns <- filter(spooky_wrd, word %in% pronouns)
pronoun_plot <- spooky_wrd %>%
filter(word %in% pronouns)
#png("../figs/pronounplot.png")
ggplot(pronoun_plot, aes(x = reorder(word, -n), y = n)) +
geom_bar(aes(color = author, fill = author), stat = "identity") +
xlab("Pronouns") +
ylab("Number of Occurences") +
theme_light()
#dev.off()
# add length column
spooky <- spooky %>%
mutate(sen_length = str_length(text))
spooky <- spooky %>%
group_by(author) %>%
mutate(Avg = round(mean(sen_length), 2)) %>%
ungroup() %>%
mutate(author = reorder(author, Avg))
# Sentence length
slength <- ggplot(spooky) +
geom_density_ridges(aes(sen_length, author, fill = author)) +
scale_x_log10() +
theme(legend.position = "none") +
labs(x = NULL) +
ggtitle("Sentence length [# characters]")
# Word length
spooky_wrd <- spooky_wrd %>%
mutate(word_length = str_length(word))
wlength <- ggplot(spooky_wrd) +
geom_density(aes(word_length, fill = author), bw = 0.05, alpha = 0.4) +
scale_x_log10() +
theme(legend.position = "none") +
ggtitle("Word length [# characters]") +
labs(x = NULL)
# Visualizations
#png("../figs/swlengths.png")
layout <- matrix(c(1, 1, 1, 1, NA, NA, 2, 2, 2, 2, 2, 2), 2, 6, byrow = TRUE)
multiplot(slength, wlength, layout = layout)
#dev.off()
total_wrds <- spooky_wrd %>%
group_by(author) %>%
summarize(total = sum(n))
spooky_wrd <- left_join(spooky_wrd, total_wrds, by = "author")
# rid of stop words
spooky_wrd_clean <- spooky_wrd %>%
anti_join(stop_words, by = "word")
# added rank and frequency values
spooky_wrd_clean <- spooky_wrd_clean %>%
group_by(author) %>%
mutate(rank = row_number(), freq = n/total)
head(spooky_wrd_clean)
# Top 10 Words Dataframes
top10 <- spooky_wrd_clean %>%
filter(rank <= 10)
#png("../figs/top10.png")
top10 %>%
ggplot(., aes(x = reorder(word, n), y = n)) +
geom_bar(aes(color = author, fill = author), stat = 'identity') +
facet_wrap(~author) +
coord_flip() +
theme_light() +
ylab("Number of Occurences") +
xlab("Most Common Words")
#dev.off()
# Word lists by author
MWSwords <- spooky_wrd_clean %>%
filter(author == "MWS") %>%
mutate(freq = n/total, rank = row_number()) %>%
arrange(desc(n))
HPLwords <- spooky_wrd_clean %>%
filter(author == "HPL") %>%
mutate(freq = n/total, rank = row_number()) %>%
arrange(desc(n))
EAPwords <- spooky_wrd_clean %>%
filter(author == "EAP") %>%
mutate(freq = n/total, rank = row_number()) %>%
arrange(desc(n))
# Word Clouds
# MWS wordcloud
#png("../figs/Workcloud_all.png")
png("~/Documents/GitHub/spring2018-project1-sophiebeiers/figs/mwsWC.png")
wordcloud(words = MWSwords$word, freq = MWSwords$freq, max.words = 100,
random.order = FALSE, rot.per = 0.35, colors = brewer.pal(6, "Dark2"))
#dev.off()
# HPL wordcloud
#png("../figs/hplWC.png")
wordcloud(words = HPLwords$word, freq = HPLwords$freq, max.words = 100,
random.order = FALSE, rot.per = 0.35, colors = brewer.pal(6, "Dark2"))
#dev.off()
# EAP wordcloud
#png("../figs/eapWC.png")
wordcloud(words = EAPwords$word, freq = EAPwords$freq, max.words = 100,
random.order = FALSE, rot.per = 0.35, colors = brewer.pal(6, "Dark2"))
#dev.off()
spooky_wrd_clean %>%
ggplot(aes(rank, freq, color = author)) +
geom_line(size = 1.1, alpha = 0.8) +
scale_x_log10() +
scale_y_log10() +
xlab("Rank") +
ylab("Word Frequency") +
theme_light()
idftf <- spooky_wrd_clean %>%
bind_tf_idf(word, author, n)
idftf <- idftf %>%
select(-total) %>%
arrange(desc(tf_idf))
#png("../figs/tfidf.png")
idftf %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(author) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(reorder(word,tf_idf), tf_idf, fill = author)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~author, ncol = 2, scales = "free") +
coord_flip() +
theme_light()
#dev.off()
pn_sentiments <- spooky_wrd_clean %>%
inner_join(get_sentiments("bing"), by = c(word = "word"))
# Negative and positive sentiments by word/ author
author_sent <- pn_sentiments %>%
count(sentiment, word, wt = n) %>%
ungroup() %>%
filter(nn >= 30) %>% # only look at words that appear more than 30 times
mutate(nn = ifelse(sentiment == "negative", -nn, nn)) %>%
mutate(word = reorder(word, nn)) %>%
ggplot(aes(word, nn, fill = sentiment)) +
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
theme_light() +
theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
ylab("Word Contribution to Sentiment") +
xlab("Words") +
facet_wrap(~author, scales = "free_x")
# Top 10 positive and negative words used
total_sent <- pn_sentiments %>%
subset(select = c(word, sentiment, n)) %>%
group_by(sentiment) %>%
top_n(10) %>%
ggplot(aes(reorder(word, n), n, fill = sentiment)) +
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution To Sentiment", x = NULL) +
ggtitle("Top Pos & Neg Words") +
theme_light() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
coord_flip()
# Total negative and positive words used by authors
author_sent2 <- pn_sentiments %>%
count(author, sentiment, wt = n) %>%
ggplot(aes(sentiment, nn, fill = sentiment)) +
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~author) +
labs(y = NULL, x = NULL) +
ggtitle("# of Pos/Neg Words")
theme_light()
#png("../figs/posnegwords.png")
layout <- matrix(c(1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3), 2, 11, byrow = TRUE)
multiplot(author_sent2, author_sent, total_sent, layout = layout)
#dev.off()
pn_sentiments2 <- spooky_wrd_clean %>%
inner_join(get_sentiments("afinn"), by = c(word = "word")) %>%
group_by(author) %>%
mutate(rank = row_number()) %>%
filter(rank < 1000) %>%
ungroup() %>%
mutate(x = n * score)
hm.palette <- colorRampPalette(rev(brewer.pal(7, 'GnBu')), space='Lab')
#png("../figs/posneghm.png")
ggplot(data = pn_sentiments2, aes(x = rank, y = author)) +
geom_tile(aes(fill = score), na.rm = TRUE) +
scale_fill_gradientn(colours = hm.palette(100)) +
labs(x = "First 1000 Most Used Words", y = "Authors")
#dev.off()
spooky_MWS <- spooky %>%
filter(author == "MWS")
bigrams <- spooky_MWS %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bi_sep <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
no_words <- c("not", "no", "never", "without")
AFINN <- get_sentiments("afinn")
no_bigram <- bi_sep %>%
filter(word1 %in% no_words) %>%
inner_join(AFINN, by = c(word2 = "word")) %>%
count(word2, score, sort = TRUE) %>%
ungroup()
#png("../figs/negwrds.png")
no_bigram %>%
mutate(contribution = n * score) %>%
arrange(desc(abs(contribution))) %>%
head(20) %>%
mutate(word2 = reorder(word2, contribution)) %>%
ggplot(aes(word2, n * score, fill = n * score > 0)) +
geom_col(show.legend = FALSE, alpha = 0.8) +
xlab("Words Preceded by Negations") +
ylab("Contribution to Sentiment") +
coord_flip() +
theme_light()
#dev.off()
# Quadgram for "love"
quadgrams <- spooky_MWS %>%
unnest_tokens(quadgram, text, token = "ngrams", n = 4)
quad_sep <- quadgrams %>%
separate(quadgram, c("word1", "word2", "word3", "word4"), sep = " ")
quad_love <- quad_sep %>%
filter(word1 == "love"| word2 == "love"| word3 == "love"| word4 == "love")
# bigram for love, later.
sub <- select(quad_love, id, author, word3, word4)
bigram_love <- sub %>%
filter(word4 == "love")
head(quad_love)
# combine words into sentences, rid of unused columns
quad_love$text <- paste(quad_love$word1,"", quad_love$word2, "", quad_love$word3, "", quad_love$word4)
sub <- select(quad_love, id, text)
# get sentiments for sentences with "love" in them
love_sent <- sub %>%
group_by(id) %>%
unnest_tokens(word, text) %>%
inner_join(get_sentiments("afinn")) %>%
group_by(id) %>%
summarise(sentiment = sum(score, na.rm = TRUE)) %>%
arrange(desc(sentiment)) %>%
mutate(sentence_num = row_number())
head(love_sent)
tail(love_sent)
# Get rid of my own stop words.
my_stop_words <- c("of", "and", "to", "the", "a", "as", "that", "by")
x <- removeWords(bigram_love$word3, my_stop_words)
bigram_love$new <- x
bigram_love$word3 <- bigram_love$new
bigram_love$new <- NA
loveplot1 <- bigram_love %>%
count(word3, word4) %>%
arrange(desc(n)) %>%
filter(n > 1& n < 20) %>%
spread(word4, n, fill = 0) %>%
ggplot(., aes(x = reorder(word3, love), love, fill = love)) +
geom_col(alpha = 0.8) +
ggtitle("Words That Come Before Love") +
xlab(NULL) +
ylab(NULL) +
labs(fill='Frequency') +
coord_flip() +
theme_light()
loveplot2 <- bigram_love %>%
count(word3, word4) %>%
arrange(desc(n)) %>%
spread(word4, n, fill = 0) %>%
inner_join(get_sentiments("afinn"), by = c(word3 = "word")) %>%
arrange(desc(score)) %>%
ggplot(., aes(x = reorder(word3, score * love), love * score, fill = love * score > 0)) +
geom_col(alpha = 0.8) +
xlab(NULL) +
ylab(NULL) +
scale_fill_discrete(name="Contribution to Sentiment", labels=c("Negative", "Positive")) +
coord_flip() +
theme_light()
#png("../figs/loveplts.png")
layout <- matrix(c(1, 1, 1, 1, 2, 2, 2, 2), 2, 4, byrow = TRUE)
multiplot(loveplot1, loveplot2, layout = layout)
#dev.off()
?help()
dtm <- spooky %>%
unnest_tokens(word, text) %>%
count(id, word) %>%
cast_dtm(id, word, n)
dtm.mat <- as.matrix(dtm)
dtm.mat <- dtm.mat[,!colnames(dtm.mat)%in%stopwords()]
df <- spooky[,c("id","author")]
MWS <- which(df$author == "MWS") # identify which are MWS
dtm_MWS <- dtm.mat[MWS, ]
set.seed(2018)
km <- kmeans(dtm_MWS, centers = 4)
names(head(sort(km$centers[4,], decreasing = TRUE), 16))
names(head(sort(km$centers[3,], decreasing = TRUE), 16))
names(head(sort(km$centers[1,], decreasing = TRUE), 16))
plot(dtm_MWS, col = km$cluster + 1, pch = 20, cex = 2)
Z <- scale(dtm_MWS)
plot(Z, col = km$cluster + 1, pch = 20, cex = 2)
km$cluster
k <- kmeans(Z, centers = 4, nstart = 20)
plot(Z, col = km$cluster, pch = 20, cex = 2)
km$cluster
km$centers
head(km$centers)
dtm.mat[ ,1:6]
Z[ ,1:6]
library(broom)
Z <- scale(dtm_MWS)
Z[ ,1:6]
glance(km)
km$betweenss / km$totss
head(km$centers)
names(head(sort(km$centers[4,], decreasing = TRUE), 16))
names(head(sort(km$centers[3,], decreasing = TRUE), 16))
names(head(sort(km$centers[2,], decreasing = TRUE), 16))
names(head(sort(km$centers[1,], decreasing = TRUE), 16))
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
packages.used <- c("ggplot2", "dplyr", "tibble", "tidyr",  "stringr", "tidytext", "topicmodels", "wordcloud", "ggridges", "sentimentr", "tm", "caret", "topicmodels", "broom")
# check packages that need to be installed.
packages.needed <- setdiff(packages.used, intersect(installed.packages()[,1], packages.used))
# install additional packages
if(length(packages.needed) > 0) {
install.packages(packages.needed, dependencies = TRUE, repos = 'http://cran.us.r-project.org')
}
library(ggplot2)
library(dplyr)
library(tibble)
library(tidyr)
library(stringr)
library(tidytext)
library(topicmodels)
library(wordcloud)
library(ggridges)
library(sentimentr)
library(tm)
library(caret)
library(topicmodels)
library(broom)
source("../lib/multiplot.R")
spooky <- read.csv('../data/spooky.csv', as.is = TRUE)
#sum(is.na(spooky)) # no NA's in data
spooky$author <- as.factor(spooky$author) # Make "author" a factor
spooky_wrd <- spooky %>%
unnest_tokens(word, text) %>%
count(author, word, sort = TRUE) %>% # sorts by most common words
ungroup()
# add length column
spooky <- spooky %>%
mutate(sen_length = str_length(text))
spooky <- spooky %>%
group_by(author) %>%
mutate(Avg = round(mean(sen_length), 2)) %>%
ungroup() %>%
mutate(author = reorder(author, Avg))
# Sentence length
slength <- ggplot(spooky) +
geom_density_ridges(aes(sen_length, author, fill = author)) +
scale_x_log10() +
theme(legend.position = "none") +
labs(x = NULL) +
ggtitle("Sentence length [# characters]")
# Word length
spooky_wrd <- spooky_wrd %>%
mutate(word_length = str_length(word))
wlength <- ggplot(spooky_wrd) +
geom_density(aes(word_length, fill = author), bw = 0.05, alpha = 0.4) +
scale_x_log10() +
theme(legend.position = "none") +
ggtitle("Word length [# characters]") +
labs(x = NULL)
# Visualizations
#png("../figs/swlengths.png")
layout <- matrix(c(1, 1, 1, 1, NA, NA, 2, 2, 2, 2, 2, 2), 2, 6, byrow = TRUE)
multiplot(slength, wlength, layout = layout)
total_wrds <- spooky_wrd %>%
group_by(author) %>%
summarize(total = sum(n))
spooky_wrd <- left_join(spooky_wrd, total_wrds, by = "author")
# rid of stop words
spooky_wrd_clean <- spooky_wrd %>%
anti_join(stop_words, by = "word")
# added rank and frequency values
spooky_wrd_clean <- spooky_wrd_clean %>%
group_by(author) %>%
mutate(rank = row_number(), freq = n/total)
head(spooky_wrd_clean)
# Top 10 Words Dataframes
top10 <- spooky_wrd_clean %>%
filter(rank <= 10)
#png("../figs/top10.png")
top10 %>%
ggplot(., aes(x = reorder(word, n), y = n)) +
geom_bar(aes(color = author, fill = author), stat = 'identity') +
facet_wrap(~author) +
coord_flip() +
theme_light() +
ylab("Number of Occurences") +
xlab("Most Common Words")
pn_sentiments <- spooky_wrd_clean %>%
inner_join(get_sentiments("bing"), by = c(word = "word"))
# Negative and positive sentiments by word/ author
author_sent <- pn_sentiments %>%
count(sentiment, word, wt = n) %>%
ungroup() %>%
filter(nn >= 30) %>% # only look at words that appear more than 30 times
mutate(nn = ifelse(sentiment == "negative", -nn, nn)) %>%
mutate(word = reorder(word, nn)) %>%
ggplot(aes(word, nn, fill = sentiment)) +
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
theme_light() +
theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
ylab("Word Contribution to Sentiment") +
xlab("Words") +
facet_wrap(~author, scales = "free_x")
# Top 10 positive and negative words used
total_sent <- pn_sentiments %>%
subset(select = c(word, sentiment, n)) %>%
group_by(sentiment) %>%
top_n(10) %>%
ggplot(aes(reorder(word, n), n, fill = sentiment)) +
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution To Sentiment", x = NULL) +
ggtitle("Top Pos & Neg Words") +
theme_light() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
coord_flip()
# Total negative and positive words used by authors
author_sent2 <- pn_sentiments %>%
count(author, sentiment, wt = n) %>%
ggplot(aes(sentiment, nn, fill = sentiment)) +
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~author) +
labs(y = NULL, x = NULL) +
ggtitle("# of Pos/Neg Words") +
theme_light()
png("~Documents/Github/spring2018-project1-sophiebeiers/figs/posnegwords.png")
layout <- matrix(c(1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3), 2, 11, byrow = TRUE)
multiplot(author_sent2, author_sent, total_sent, layout = layout)
dev.off()
png("~/Documents/Github/spring2018-project1-sophiebeiers/figs/posnegwords.png")
layout <- matrix(c(1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3), 2, 11, byrow = TRUE)
multiplot(author_sent2, author_sent, total_sent, layout = layout)
dev.off()
